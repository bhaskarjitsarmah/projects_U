{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "\n",
    "The MapReduce programming technique was designed to analyze massive data sets across a cluster. In this Jupyter notebook, you'll get a sense for how Hadoop MapReduce works; however, this notebook will run locally rather than on a cluster.\n",
    "\n",
    "The biggest difference between Hadoop and Spark is that Spark tries to do as many calculations as possible in memory, which avoids moving data back and forth across a cluster. Hadoop writes intermediate calculations out to disk, which can be less efficient. Hadoop is an older technology than Spark and one of the cornerstone big data technologies.\n",
    "\n",
    "If you click on the Jupyter notebook logo at the top of the workspace, you'll be taken to the workspace directory. There you will see a file called \"songplays.txt\". This is a text file where each line represents a song that was played in the Sparkify app. The MapReduce code will count how many times each song was played. In other words, the code counts how many times the song title appears in the list.\n",
    "\n",
    "\n",
    "# MapReduce versus Hadoop MapReduce\n",
    "\n",
    "Don't get confused by the terminology! MapReduce is a programming technique. Hadoop MapReduce is a specific implementation of the programming technique.\n",
    "\n",
    "Some of the syntax will look a bit funny, so be sure to read the explanation and comments for each section. You'll learn more about the syntax in later lessons. \n",
    "\n",
    "Run each of the code cells below to see the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mrjob\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/55/76/39f7783033d2ef0ecf301f29b47015c47fd5dd6e7cde01fe476a7fa1d2d6/mrjob-0.6.9-py2.py3-none-any.whl (430kB)\n",
      "\u001b[K    100% |████████████████████████████████| 430kB 10.0MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: boto3>=1.4.6 in /opt/conda/lib/python3.6/site-packages (from mrjob) (1.9.7)\n",
      "Collecting google-cloud-logging>=1.9.0 (from mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/f6/bdfa6affc2705616bb172603589eaa5f36fc79362236a073fd2c2c0ff017/google_cloud_logging-1.11.0-py2.py3-none-any.whl (132kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 24.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-cloud-storage>=1.13.1 (from mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e2/4e/aee59b19321eb1063317c2e6fa4c2f3cfe21740586de78578eedbd2bed3d/google_cloud_storage-1.16.1-py2.py3-none-any.whl (65kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 17.2MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /opt/conda/lib/python3.6/site-packages (from mrjob) (3.12)\n",
      "Collecting google-cloud-dataproc>=0.3.0 (from mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/f8/6874c9db1a2011f35c2ab9293053dcfc206393e2b7f191b08b51148fb8ed/google_cloud_dataproc-0.4.0-py2.py3-none-any.whl (237kB)\n",
      "\u001b[K    100% |████████████████████████████████| 245kB 22.7MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: botocore>=1.6.0 in /opt/conda/lib/python3.6/site-packages (from mrjob) (1.12.7)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.4.6->mrjob) (0.9.3)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /opt/conda/lib/python3.6/site-packages (from boto3>=1.4.6->mrjob) (0.1.13)\n",
      "Collecting google-cloud-core<2.0dev,>=1.0.0 (from google-cloud-logging>=1.9.0->mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/98/7f/ff56aec313787577e262d5a2e306c04aef61c5c274699ff9fb40095e6691/google_cloud_core-1.0.2-py2.py3-none-any.whl\n",
      "Collecting google-api-core[grpc]<2.0.0dev,>=1.6.0 (from google-cloud-logging>=1.9.0->mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/10/d6/8b1e8d79a8a56649af3a094e3d90dd213278da942f36d831b57c0ca4a503/google_api_core-1.11.1-py2.py3-none-any.whl (66kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 17.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting google-resumable-media>=0.3.1 (from google-cloud-storage>=1.13.1->mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/e2/5d/4bc5c28c252a62efe69ed1a1561da92bd5af8eca0cdcdf8e60354fae9b29/google_resumable_media-0.3.2-py2.py3-none-any.whl\n",
      "Collecting google-auth>=1.2.0 (from google-cloud-storage>=1.13.1->mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c5/9b/ed0516cc1f7609fb0217e3057ff4f0f9f3e3ce79a369c6af4a6c5ca25664/google_auth-1.6.3-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 18.4MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: docutils>=0.10 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.6.0->mrjob) (0.14)\n",
      "Requirement already satisfied: urllib3<1.24,>=1.20 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.6.0->mrjob) (1.22)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.6/site-packages (from botocore>=1.6.0->mrjob) (2.6.1)\n",
      "Collecting googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/eb/ee/e59e74ecac678a14d6abefb9054f0bbcb318a6452a30df3776f133886d7d/googleapis-common-protos-1.6.0.tar.gz\n",
      "Requirement already satisfied: six>=1.10.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (1.11.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (2.18.4)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (38.4.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (2017.3)\n",
      "Requirement already satisfied: protobuf>=3.4.0 in /opt/conda/lib/python3.6/site-packages (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (3.5.1)\n",
      "Collecting grpcio<2.0dev,>=1.8.2; extra == \"grpc\" (from google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/83/18f374294bf34128a448ee2fae37651f943b0b5fa473b5b3aff262c15bf8/grpcio-1.21.1-cp36-cp36m-manylinux1_x86_64.whl (2.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 2.2MB 7.3MB/s eta 0:00:01    25% |████████▎                       | 563kB 32.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1-modules>=0.2.1 (from google-auth>=1.2.0->google-cloud-storage>=1.13.1->mrjob)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/f0/b03e00ce9fddf4827c42df1c3ce10c74eadebfb706231e8d6d1c356a4062/pyasn1_modules-0.2.5-py2.py3-none-any.whl (74kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 18.0MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting cachetools>=2.0.0 (from google-auth>=1.2.0->google-cloud-storage>=1.13.1->mrjob)\n",
      "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: rsa>=3.1.4 in /opt/conda/lib/python3.6/site-packages (from google-auth>=1.2.0->google-cloud-storage>=1.13.1->mrjob) (3.4.2)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (3.0.4)\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.6.0->google-cloud-logging>=1.9.0->mrjob) (2017.11.5)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.1 in /opt/conda/lib/python3.6/site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2.0->google-cloud-storage>=1.13.1->mrjob) (0.4.4)\n",
      "Building wheels for collected packages: googleapis-common-protos\n",
      "  Running setup.py bdist_wheel for googleapis-common-protos ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9e/3d/a2/1bec8bb7db80ab3216dbc33092bb7ccd0debfb8ba42b5668d5\n",
      "Successfully built googleapis-common-protos\n",
      "\u001b[31mgoogleapis-common-protos 1.6.0 has requirement protobuf>=3.6.0, but you'll have protobuf 3.5.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: googleapis-common-protos, pyasn1-modules, cachetools, google-auth, grpcio, google-api-core, google-cloud-core, google-cloud-logging, google-resumable-media, google-cloud-storage, google-cloud-dataproc, mrjob\n",
      "Successfully installed cachetools-3.1.1 google-api-core-1.11.1 google-auth-1.6.3 google-cloud-core-1.0.2 google-cloud-dataproc-0.4.0 google-cloud-logging-1.11.0 google-cloud-storage-1.16.1 google-resumable-media-0.3.2 googleapis-common-protos-1.6.0 grpcio-1.21.1 mrjob-0.6.9 pyasn1-modules-0.2.5\n"
     ]
    }
   ],
   "source": [
    "# Install mrjob library. This package is for running MapReduce jobs with Python\n",
    "# In Jupyter notebooks, \"!\" runs terminal commands from inside notebooks \n",
    "\n",
    "! pip install mrjob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting wordcount.py\n"
     ]
    }
   ],
   "source": [
    "%%file wordcount.py\n",
    "# %%file is an Ipython magic function that saves the code cell as a file\n",
    "\n",
    "from mrjob.job import MRJob # import the mrjob library\n",
    "\n",
    "class MRSongCount(MRJob):\n",
    "    \n",
    "    # the map step: each line in the txt file is read as a key, value pair\n",
    "    # in this case, each line in the txt file only contains a value but no key\n",
    "    # _ means that in this case, there is no key for each line\n",
    "    def mapper(self, _, song):\n",
    "        # output each line as a tuple of (song_names, 1) \n",
    "        yield (song, 1)\n",
    "\n",
    "    # the reduce step: combine all tuples with the same key\n",
    "    # in this case, the key is the song name\n",
    "    # then sum all the values of the tuple, which will give the total song plays\n",
    "    def reducer(self, key, values):\n",
    "        yield (key, sum(values))\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    MRSongCount.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No configs found; falling back on auto-configuration\n",
      "No configs specified for inline runner\n",
      "Creating temp directory /tmp/wordcount.root.20190617.171949.707783\n",
      "Running step 1 of 1...\n",
      "job output is in /tmp/wordcount.root.20190617.171949.707783/output\n",
      "Streaming final output from /tmp/wordcount.root.20190617.171949.707783/output...\n",
      "\"Deep Dreams\"\t1131\n",
      "\"Broken Networks\"\t510\n",
      "\"Data House Rock\"\t828\n",
      "Removing temp directory /tmp/wordcount.root.20190617.171949.707783...\n"
     ]
    }
   ],
   "source": [
    "# run the code as a terminal command\n",
    "! python wordcount.py songplays.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of what happens in the code.\n",
    "\n",
    "There is a list of songs in songplays.txt that looks like the following:\n",
    "\n",
    "Deep Dreams\n",
    "Data House Rock\n",
    "Deep Dreams\n",
    "Data House Rock\n",
    "Broken Networks\n",
    "Data House Rock\n",
    "etc.....\n",
    "\n",
    "During the map step, the code reads in the txt file one line at a time. The map steps outputs a set of tuples that look like this:\n",
    "\n",
    "(Deep Dreams, 1)  \n",
    "(Data House Rock, 1)  \n",
    "(Deep Dreams, 1)  \n",
    "(Data House Rock, 1)  \n",
    "(Broken Networks, 1)  \n",
    "(Data House Rock, 1)  \n",
    "etc.....\n",
    "\n",
    "Finally, the reduce step combines all of the values by keys and sums the values:  \n",
    "\n",
    "(Deep Dreams, \\[1, 1, 1, 1, 1, 1, ... \\])  \n",
    "(Data House Rock, \\[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\\])  \n",
    "(Broken Networks, \\[1, 1, 1, ...\\]  \n",
    "\n",
    "With the output \n",
    "\n",
    "(Deep Dreams, 1131)  \n",
    "(Data House Rock, 510)  \n",
    "(Broken Networks, 828)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
