{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3: Smart Beta Portfolio and Portfolio Optimization\n",
    "## Instructions\n",
    "Each problem consists of a function to implement and instructions on how to implement the function.  The parts of the function that need to be implemented are marked with a `# TODO` comment. After implementing the function, run the cell to test it against the unit tests we've provided. For each problem, we provide one or more unit tests from our `project_tests` package. These unit tests won't tell you if your answer is correct, but will warn you of any major errors. Your code will be checked for the correct solution when you submit it Udacity.\n",
    "\n",
    "## Packages\n",
    "When you implement the functions, you'll only need to use the [Pandas](https://pandas.pydata.org/) and [Numpy](http://www.numpy.org/) packages. Don't import any other packages, otherwise the grader willn't be able to run your code.\n",
    "\n",
    "The other packages that we're importing is `helper` and `project_tests`. These are custom packages built to help you solve the problems.  The `helper` module contains utility functions and graph functions. The `project_tests` contains the unit tests for all the problems.\n",
    "### Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colour==0.1.5 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 1))\n",
      "Collecting cvxopt==1.1.9 (from -r requirements.txt (line 2))\n",
      "  Downloading https://files.pythonhosted.org/packages/91/2f/eed1cedf02cc83c7fcab357dbda76237f8f3ba881186cfa33dcdfdc153e8/cvxopt-1.1.9-cp36-cp36m-manylinux1_x86_64.whl (16.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 16.1MB 39kB/s  eta 0:00:01  7% |██▍                             | 1.2MB 8.8MB/s eta 0:00:02    25% |████████                        | 4.1MB 19.8MB/s eta 0:00:01    31% |██████████                      | 5.1MB 28.5MB/s eta 0:00:01    37% |████████████▏                   | 6.1MB 19.2MB/s eta 0:00:01    64% |████████████████████▋           | 10.4MB 19.5MB/s eta 0:00:01    71% |███████████████████████         | 11.6MB 27.8MB/s eta 0:00:01    83% |██████████████████████████▉     | 13.5MB 17.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cycler==0.10.0 in /opt/conda/lib/python3.6/site-packages/cycler-0.10.0-py3.6.egg (from -r requirements.txt (line 3))\n",
      "Collecting matplotlib==2.1.1 (from -r requirements.txt (line 4))\n",
      "  Downloading https://files.pythonhosted.org/packages/34/50/d1649dafaecc91e360b1ca8defebb25f865e29928a98bc7d42ba3b1350e5/matplotlib-2.1.1-cp36-cp36m-manylinux1_x86_64.whl (15.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 15.0MB 43kB/s  eta 0:00:01   20% |██████▋                         | 3.1MB 23.9MB/s eta 0:00:01    28% |█████████▏                      | 4.3MB 24.2MB/s eta 0:00:01    52% |████████████████▉               | 7.9MB 27.3MB/s eta 0:00:01    61% |███████████████████▋            | 9.2MB 25.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy==1.13.3 (from -r requirements.txt (line 5))\n",
      "  Downloading https://files.pythonhosted.org/packages/57/a7/e3e6bd9d595125e1abbe162e323fd2d06f6f6683185294b79cd2cdb190d5/numpy-1.13.3-cp36-cp36m-manylinux1_x86_64.whl (17.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 17.0MB 37kB/s  eta 0:00:01 0% |▏                               | 71kB 13.3MB/s eta 0:00:02    6% |██                              | 1.0MB 19.9MB/s eta 0:00:01    12% |████                            | 2.1MB 22.2MB/s eta 0:00:01    31% |██████████▎                     | 5.4MB 22.0MB/s eta 0:00:01    38% |████████████▎                   | 6.5MB 21.6MB/s eta 0:00:01    44% |██████████████▎                 | 7.6MB 22.0MB/s eta 0:00:01    51% |████████████████▍               | 8.7MB 21.6MB/s eta 0:00:01    57% |██████████████████▌             | 9.8MB 21.6MB/s eta 0:00:01    87% |████████████████████████████    | 14.9MB 27.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pandas==0.21.1 (from -r requirements.txt (line 6))\n",
      "  Downloading https://files.pythonhosted.org/packages/3a/e1/6c514df670b887c77838ab856f57783c07e8760f2e3d5939203a39735e0e/pandas-0.21.1-cp36-cp36m-manylinux1_x86_64.whl (26.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 26.2MB 23kB/s  eta 0:00:01  9% |███                             | 2.5MB 23.3MB/s eta 0:00:02    16% |█████▎                          | 4.3MB 14.1MB/s eta 0:00:02    22% |███████▎                        | 6.0MB 16.7MB/s eta 0:00:02    26% |████████▋                       | 7.0MB 20.4MB/s eta 0:00:01    29% |█████████▌                      | 7.8MB 16.1MB/s eta 0:00:02    37% |███████████▉                    | 9.7MB 21.6MB/s eta 0:00:01    45% |██████████████▋                 | 12.0MB 22.5MB/s eta 0:00:01    49% |███████████████▉                | 13.0MB 22.4MB/s eta 0:00:01    53% |█████████████████               | 14.0MB 21.7MB/s eta 0:00:01    60% |███████████████████▌            | 16.0MB 18.9MB/s eta 0:00:01    65% |█████████████████████           | 17.2MB 23.9MB/s eta 0:00:01    68% |██████████████████████          | 18.1MB 19.6MB/s eta 0:00:01    72% |███████████████████████▎        | 19.1MB 22.6MB/s eta 0:00:01    79% |█████████████████████████▋      | 21.0MB 24.2MB/s eta 0:00:01    88% |████████████████████████████▏   | 23.1MB 22.5MB/s eta 0:00:01    95% |██████████████████████████████▋ | 25.1MB 21.8MB/s eta 0:00:01    99% |███████████████████████████████▉| 26.1MB 24.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting plotly==2.2.3 (from -r requirements.txt (line 7))\n",
      "  Downloading https://files.pythonhosted.org/packages/99/a6/8214b6564bf4ace9bec8a26e7f89832792be582c042c47c912d3201328a0/plotly-2.2.3.tar.gz (1.1MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.1MB 557kB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: pyparsing==2.2.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 8))\n",
      "Requirement already satisfied: python-dateutil==2.6.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 9))\n",
      "Requirement already satisfied: pytz==2017.3 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 10))\n",
      "Collecting quandl==3.3.0 (from -r requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/47/8c/b61f5c1e9167f4c1c1c2b86991bbbac51a2bd937b36cbc4cc39248dfb2d1/Quandl-3.3.0-py2.py3-none-any.whl\n",
      "Collecting scipy==1.0.0 (from -r requirements.txt (line 12))\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/5e/caa01ba7be11600b6a9d39265440d7b3be3d69206da887c42bef049521f2/scipy-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (50.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 50.0MB 11kB/s  eta 0:00:01  0% |▏                               | 235kB 7.9MB/s eta 0:00:07    2% |▊                               | 1.1MB 17.6MB/s eta 0:00:03    3% |█▏                              | 1.8MB 16.7MB/s eta 0:00:03    6% |██▏                             | 3.4MB 16.7MB/s eta 0:00:03    10% |███▍                            | 5.2MB 19.7MB/s eta 0:00:03    12% |███▉                            | 6.0MB 17.1MB/s eta 0:00:03    15% |█████                           | 7.9MB 18.9MB/s eta 0:00:03    19% |██████▎                         | 9.9MB 20.1MB/s eta 0:00:02    27% |████████▊                       | 13.7MB 19.7MB/s eta 0:00:02    31% |██████████                      | 15.7MB 20.5MB/s eta 0:00:02    33% |██████████▊                     | 16.7MB 15.2MB/s eta 0:00:03    35% |███████████▎                    | 17.7MB 21.8MB/s eta 0:00:02    39% |████████████▋                   | 19.7MB 19.3MB/s eta 0:00:02    41% |█████████████▏                  | 20.6MB 21.8MB/s eta 0:00:02    45% |██████████████▌                 | 22.6MB 23.5MB/s eta 0:00:02    50% |████████████████                | 25.0MB 16.7MB/s eta 0:00:02    52% |████████████████▋               | 26.0MB 22.1MB/s eta 0:00:02    57% |██████████████████▌             | 28.9MB 21.5MB/s eta 0:00:01    59% |███████████████████▏            | 29.9MB 19.1MB/s eta 0:00:02    63% |████████████████████▍           | 31.9MB 21.6MB/s eta 0:00:01    65% |█████████████████████           | 32.9MB 22.1MB/s eta 0:00:01    69% |██████████████████████▎         | 34.8MB 19.6MB/s eta 0:00:01    73% |███████████████████████▌        | 36.7MB 20.6MB/s eta 0:00:01    75% |████████████████████████▏       | 37.7MB 19.6MB/s eta 0:00:01    78% |█████████████████████████▎      | 39.5MB 18.0MB/s eta 0:00:01    80% |█████████████████████████▉      | 40.5MB 17.8MB/s eta 0:00:01    82% |██████████████████████████▌     | 41.5MB 22.1MB/s eta 0:00:01    87% |███████████████████████████▉    | 43.5MB 19.9MB/s eta 0:00:01    89% |████████████████████████████▌   | 44.6MB 19.8MB/s eta 0:00:01    91% |█████████████████████████████▏  | 45.6MB 21.9MB/s eta 0:00:01    93% |█████████████████████████████▉  | 46.7MB 22.7MB/s eta 0:00:01    99% |████████████████████████████████| 49.9MB 16.1MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn==0.19.1 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 13))\n",
      "Requirement already satisfied: six==1.11.0 in /opt/conda/lib/python3.6/site-packages (from -r requirements.txt (line 14))\n",
      "Collecting tqdm==4.19.5 (from -r requirements.txt (line 15))\n",
      "  Downloading https://files.pythonhosted.org/packages/71/3c/341b4fa23cb3abc335207dba057c790f3bb329f6757e1fcd5d347bcf8308/tqdm-4.19.5-py2.py3-none-any.whl (51kB)\n",
      "\u001b[K    100% |████████████████████████████████| 61kB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: decorator>=4.0.6 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: nbformat>=4.2 in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from plotly==2.2.3->-r requirements.txt (line 7))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting inflection>=0.3.1 (from quandl==3.3.0->-r requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/d5/35/a6eb45b4e2356fe688b21570864d4aa0d0a880ce387defe9c589112077f8/inflection-0.3.1.tar.gz\n",
      "Requirement already satisfied: pyOpenSSL in /opt/conda/lib/python3.6/site-packages (from quandl==3.3.0->-r requirements.txt (line 11))\n",
      "Collecting more-itertools (from quandl==3.3.0->-r requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/85/40/90c3b0393e12b9827381004224de8814686e3d7182f9d4182477f600826d/more_itertools-4.2.0-py3-none-any.whl (45kB)\n",
      "\u001b[K    100% |████████████████████████████████| 51kB 3.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ndg-httpsclient (from quandl==3.3.0->-r requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/78/60/1458ed478eb5777498ca57f4fabf2cf9328ac43e5f6db7839cf73704f3a6/ndg_httpsclient-0.5.0-py3-none-any.whl\n",
      "Collecting pyasn1 (from quandl==3.3.0->-r requirements.txt (line 11))\n",
      "  Downloading https://files.pythonhosted.org/packages/a0/70/2c27740f08e477499ce19eefe05dbcae6f19fdc49e9e82ce4768be0643b9/pyasn1-0.4.3-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K    100% |████████████████████████████████| 81kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython-genutils in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: traitlets>=4.1 in /opt/conda/lib/python3.6/site-packages (from nbformat>=4.2->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->plotly==2.2.3->-r requirements.txt (line 7))\n",
      "Requirement already satisfied: cryptography>=1.9 in /opt/conda/lib/python3.6/site-packages (from pyOpenSSL->quandl==3.3.0->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /opt/conda/lib/python3.6/site-packages (from cryptography>=1.9->pyOpenSSL->quandl==3.3.0->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: cffi>=1.7 in /opt/conda/lib/python3.6/site-packages (from cryptography>=1.9->pyOpenSSL->quandl==3.3.0->-r requirements.txt (line 11))\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.6/site-packages (from cffi>=1.7->cryptography>=1.9->pyOpenSSL->quandl==3.3.0->-r requirements.txt (line 11))\n",
      "Building wheels for collected packages: plotly, inflection\n",
      "  Running setup.py bdist_wheel for plotly ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/98/54/81/dd92d5b0858fac680cd7bdb8800eb26c001dd9f5dc8b1bc0ba\n",
      "  Running setup.py bdist_wheel for inflection ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/9f/5a/d3/6fc3bf6516d2a3eb7e18f9f28b472110b59325f3f258fe9211\n",
      "Successfully built plotly inflection\n",
      "Installing collected packages: cvxopt, numpy, matplotlib, pandas, plotly, inflection, more-itertools, pyasn1, ndg-httpsclient, quandl, scipy, tqdm\n",
      "  Found existing installation: numpy 1.12.1\n",
      "    Uninstalling numpy-1.12.1:\n",
      "      Successfully uninstalled numpy-1.12.1\n",
      "  Found existing installation: matplotlib 2.1.0\n",
      "    Uninstalling matplotlib-2.1.0:\n",
      "      Successfully uninstalled matplotlib-2.1.0\n",
      "  Found existing installation: pandas 0.20.3\n",
      "    Uninstalling pandas-0.20.3:\n",
      "      Successfully uninstalled pandas-0.20.3\n",
      "  Found existing installation: plotly 2.0.15\n",
      "    Uninstalling plotly-2.0.15:\n",
      "      Successfully uninstalled plotly-2.0.15\n",
      "  Found existing installation: scipy 0.19.1\n",
      "    Uninstalling scipy-0.19.1:\n",
      "      Successfully uninstalled scipy-0.19.1\n",
      "  Found existing installation: tqdm 4.11.2\n",
      "    Uninstalling tqdm-4.11.2:\n",
      "      Successfully uninstalled tqdm-4.11.2\n",
      "Successfully installed cvxopt-1.1.9 inflection-0.3.1 matplotlib-2.1.1 more-itertools-4.2.0 ndg-httpsclient-0.5.0 numpy-1.13.3 pandas-0.21.1 plotly-2.2.3 pyasn1-0.4.3 quandl-3.3.0 scipy-1.0.0 tqdm-4.19.5\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ],
      "text/vnd.plotly.v1+html": [
       "<script>requirejs.config({paths: { 'plotly': ['https://cdn.plot.ly/plotly-latest.min']},});if(!window.Plotly) {{require(['plotly'],function(plotly) {window.Plotly=plotly;});}}</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import helper\n",
    "import project_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Market Data\n",
    "The data source we'll be using is the [Wiki End of Day data](https://www.quandl.com/databases/WIKIP) hosted at [Quandl](https://www.quandl.com). This contains data for many stocks, but we'll just be looking at the S&P 500 stocks. We'll also make things a little easier to solve by narrowing our range of time from 2007-06-30 to 2017-09-30.\n",
    "### Set API Key\n",
    "Set the `quandl.ApiConfig.api_key ` variable to your Quandl api key. You can find your Quandl api key [here](https://www.quandl.com/account/api)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl\n",
    "\n",
    "# TODO: Add your Quandl API Key\n",
    "quandl.ApiConfig.api_key  = 'r4mgK1hxD11kLoFtRsso'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "snp500_file_path = 'data/tickers_SnP500.txt'\n",
    "wiki_file_path = 'data/WIKI_PRICES.csv'\n",
    "start_date, end_date = '2013-07-01', '2017-06-30'\n",
    "use_columns = ['date', 'ticker', 'adj_close', 'adj_volume', 'ex-dividend']\n",
    "\n",
    "if not os.path.exists(wiki_file_path):\n",
    "    with open(snp500_file_path) as f:\n",
    "        tickers = f.read().split()\n",
    "    \n",
    "    print('Downloading data...')\n",
    "    helper.download_quandl_dataset('WIKI', 'PRICES', wiki_file_path, use_columns, tickers, start_date, end_date)\n",
    "    print('Data downloaded')\n",
    "else:\n",
    "    print('Data already downloaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "snp500_file_path = 'data/tickers_SnP500.txt'\n",
    "wiki_file_path = 'data/WIKI_PRICES.csv'\n",
    "start_date, end_date = '2013-07-01', '2017-06-30'\n",
    "use_columns = ['date', 'ticker', 'adj_close', 'adj_volume', 'ex-dividend']\n",
    "\n",
    "if not os.path.exists(wiki_file_path):\n",
    "    with open(snp500_file_path) as f:\n",
    "        tickers = f.read().split()\n",
    "        \n",
    "    print('Downloading Data...')\n",
    "    helper.download_quandl_dataset('WIKI', 'PRICES', wiki_file_path, use_columns, tickers, start_date, end_date)\n",
    "    print('Data downloaded')\n",
    "else:\n",
    "    print('Data already downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(wiki_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Universe\n",
    "We'll be selecting dollar volume stocks for our stock universe. This universe is similar to large market cap stocks, because they are the highly liquid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_top_dollar = 0.2\n",
    "high_volume_symbols = helper.large_dollar_volume_stocks(df, 'adj_close', 'adj_volume', percent_top_dollar)\n",
    "df = df[df['ticker'].isin(high_volume_symbols)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2-D Matrices\n",
    "In the previous projects, we used a [multiindex](https://pandas.pydata.org/pandas-docs/stable/advanced.html) to store all the data in a single dataframe. As you work with larger datasets, it come infeasable to store all the data in memory. Starting with this project, we'll be storing all our data as 2-D matrices to match what you'll be expecting in the real world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "close = df.reset_index().pivot(index='ticker', columns='date', values='adj_close')\n",
    "volume = df.reset_index().pivot(index='ticker', columns='date', values='adj_volume')\n",
    "ex_dividend = df.reset_index().pivot(index='ticker', columns='date', values='ex-dividend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "To see what one of these 2-d matrices looks like, let's take a look at the closing prices matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.print_dataframe(close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Smart Beta Portfolio\n",
    "In Part 1 of this project, you'll build a smart beta portfolio using dividend yield. To see how well it performs, you'll compare this portfolio to an index.\n",
    "## Index Weights\n",
    "After building the smart beta portfolio, should compare it to a similar strategy or index.\n",
    "\n",
    "Implement `generate_dollar_volume_weights` to generate the weights for this index. For each date, generate the weights based on dollar volume traded for that date. For example, assume the following is dollar volume traded data:\n",
    "\n",
    "|          | 10/02/2010 | 10/03/2010 |\n",
    "|----------|------------|------------|\n",
    "| **AAPL** |      2     |      2     |\n",
    "| **BBC**  |      5     |      6     |\n",
    "| **GGL**  |      1     |      2     |\n",
    "| **ZGB**  |      6     |      5     |\n",
    "\n",
    "The weights should be the following:\n",
    "\n",
    "|          | 10/02/2010 | 10/03/2010 |\n",
    "|----------|------------|------------|\n",
    "| **AAPL** |    0.142   |    0.133   |\n",
    "| **BBC**  |    0.357   |    0.400   |\n",
    "| **GGL**  |    0.071   |    0.133   |\n",
    "| **ZGB**  |    0.428   |    0.333   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dollar_volume_weights(close, volume):\n",
    "    \"\"\"\n",
    "    Generate dollar volume weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "    volume : str\n",
    "        Volume for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dollar_volume_weights : DataFrame\n",
    "        The dollar volume weights for each ticker and date\n",
    "    \"\"\"\n",
    "    assert close.index.equals(volume.index)\n",
    "    assert close.columns.equals(volume.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_dollar_volume_weights(generate_dollar_volume_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the index weights using `generate_dollar_volume_weights` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weights = generate_dollar_volume_weights(close, volume)\n",
    "helper.plot_weights(index_weights, 'Index Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETF Weights\n",
    "Now that we have the index weights, it's time to build the weights for the smart beta ETF. Let's build an ETF portfolio that is based on dividends. This is a common factor used to build portfolios. Unlike most portfolios, we'll be using a single factor for simplicity.\n",
    "\n",
    "Implement `calculate_dividend_weights` to returns the weights for each stock based on its total dividend yield over time. This is similar to generating the weight for the index, but it's dividend data instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dividend_weights(ex_dividend):\n",
    "    \"\"\"\n",
    "    Calculate dividend weights.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    ex_dividend : DataFrame\n",
    "        Ex-dividend for each stock and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dividend_weights : DataFrame\n",
    "        Weights for each stock and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_calculate_dividend_weights(calculate_dividend_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the ETF weights using `calculate_dividend_weights` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "etf_weights = calculate_dividend_weights(ex_dividend)\n",
    "helper.plot_weights(etf_weights, 'ETF Weights')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns\n",
    "Implement `generate_returns` to generate the returns. Note this isn't log returns. Since we're not dealing with volatility, we don't have to use log returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_returns(close):\n",
    "    \"\"\"\n",
    "    Generate returns for ticker and date.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    close : DataFrame\n",
    "        Close price for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    returns : Dataframe\n",
    "        The returns for each ticker and date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_returns(generate_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the closing returns using `generate_returns` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = generate_returns(close)\n",
    "helper.plot_returns(returns, 'Close Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted Returns\n",
    "With the returns of each stock computed, we can use it to compute the returns for for an index or ETF. Implement `generate_weighted_returns` to create weighted returns using returns and weights for an Index or ETF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_weighted_returns(returns, weights):\n",
    "    \"\"\"\n",
    "    Generate weighted returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weights : DataFrame\n",
    "        Weights for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    weighted_returns : DataFrame\n",
    "        Weighted returns for each ticker and date\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weights.index)\n",
    "    assert returns.columns.equals(weights.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_generate_weighted_returns(generate_weighted_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the etf and index returns using `generate_weighted_returns` and view them using a heatmap."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weighted_returns = generate_weighted_returns(returns, index_weights)\n",
    "etf_weighted_returns = generate_weighted_returns(returns, etf_weights)\n",
    "helper.plot_returns(index_weighted_returns, 'Index Returns')\n",
    "helper.plot_returns(etf_weighted_returns, 'ETF Returns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cumulative Returns\n",
    "Implement `calculate_cumulative_returns` to calculate the cumulative returns over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cumulative_returns(returns):\n",
    "    \"\"\"\n",
    "    Calculate cumulative returns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    cumulative_returns : Pandas Series\n",
    "        Cumulative returns for each date\n",
    "    \"\"\"\n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_calculate_cumulative_returns(calculate_cumulative_returns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's generate the etf and index cumulative returns using `calculate_cumulative_returns` and compare the two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_weighted_cumulative_returns = calculate_cumulative_returns(index_weighted_returns)\n",
    "etf_weighted_cumulative_returns = calculate_cumulative_returns(etf_weighted_returns)\n",
    "helper.plot_benchmark_returns(index_weighted_cumulative_returns, etf_weighted_cumulative_returns, 'Smart Beta ETF vs Index')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tracking Error\n",
    "In order to check the performance of the smart beta portfolio, we can compare it against the index. Let's generate the tracking error using the helper function's `tracking_error` and graph it over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_beta_tracking_error = helper.tracking_error(index_weighted_cumulative_returns, etf_weighted_cumulative_returns)\n",
    "helper.plot_tracking_error(smart_beta_tracking_error, 'Smart Beta Tracking Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Portfolio Optimization\n",
    "In Part 2, you'll optimize the index you created in part 1. You'll use `cvxopt` to optimize the convex problem of finding the optimal weights for the portfolio. Just like before, we'll compare these results to the index.\n",
    "## Covariance\n",
    "Implement `get_covariance` to calculate the covariance of `returns` and `weighted_index_returns`. We'll use this to feed into our convex optimization function. By using covariance, we can prevent the optimizer from going all in on a few stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_covariance(returns, weighted_index_returns):\n",
    "    \"\"\"\n",
    "    Calculate covariance matrices.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weighted_index_returns : DataFrame\n",
    "        Weighted index returns for each ticker and date\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    xtx, xty  : (2 dimensional Ndarray, 1 dimensional Ndarray)\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weighted_index_returns.index)\n",
    "    assert returns.columns.equals(weighted_index_returns.columns)\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None, None\n",
    "\n",
    "project_tests.test_get_covariance(get_covariance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Data\n",
    "Let's look the the covariance generated from `get_covariance`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtx, xty = get_covariance(returns, index_weighted_returns)\n",
    "xtx = pd.DataFrame(xtx, returns.index, returns.index)\n",
    "xty = pd.Series(xty, returns.index)\n",
    "helper.plot_covariance(xty, xtx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quadratic Programming\n",
    "Now that you have the covariance, we can use this to optimize the weights. Run the following cell to generate optimal weights using helper function's `solve_qp`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_optim_etf_weights = helper.solve_qp(xtx.values, xty.values)\n",
    "raw_optim_etf_weights_per_date = np.tile(raw_optim_etf_weights, (len(returns.columns), 1))\n",
    "optim_etf_weights = pd.DataFrame(raw_optim_etf_weights_per_date.T, returns.index, returns.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimized Portfolio\n",
    "With our optimized etf weights built using quadratic programming, let's compare it to the index. Run the next cell to calculate the optimized etf returns and compare the returns to the index returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_etf_returns = generate_weighted_returns(returns, optim_etf_weights)\n",
    "optim_etf_cumulative_returns = calculate_cumulative_returns(optim_etf_returns)\n",
    "helper.plot_benchmark_returns(index_weighted_cumulative_returns, optim_etf_cumulative_returns, 'Optimized ETF vs Index')\n",
    "\n",
    "optim_etf_tracking_error = helper.tracking_error(index_weighted_cumulative_returns, optim_etf_cumulative_returns)\n",
    "helper.plot_tracking_error(optim_etf_tracking_error, 'Optimized ETF Tracking Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebalance Portfolio\n",
    "The optimized etf portfolio used different weights for each day. After calculating in transaction fees, this amount of turnover to the portfolio can reduce the total returns. Let's find the optimal times to rebalance the portfolio instead of doing it every day.\n",
    "\n",
    "Implement `rebalance_portfolio` to rebalance a portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rebalance_portfolio(returns, weighted_index_returns, shift_size, chunk_size):\n",
    "    \"\"\"\n",
    "    Get weights for each rebalancing of the portfolio.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    returns : DataFrame\n",
    "        Returns for each ticker and date\n",
    "    weighted_index_returns : DataFrame\n",
    "        Weighted index returns for each ticker and date\n",
    "    shift_size : int\n",
    "        The number of days between each rebalance\n",
    "    chunk_size : int\n",
    "        The number of days to look in the past for rebalancing\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_rebalance_weights  : list of Ndarrays\n",
    "        The etf weights for each point they are rebalanced\n",
    "    \"\"\"\n",
    "    assert returns.index.equals(weighted_index_returns.index)\n",
    "    assert returns.columns.equals(weighted_index_returns.columns)\n",
    "    assert shift_size > 0\n",
    "    assert chunk_size >= 0\n",
    "    \n",
    "    #TODO: Implement function\n",
    "    \n",
    "    return None\n",
    "\n",
    "project_tests.test_rebalance_portfolio(rebalance_portfolio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to rebalance the portfolio using `rebalance_portfolio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "shift_size = 5\n",
    "all_rebalance_weights = rebalance_portfolio(returns, index_weighted_returns, shift_size, chunk_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Rebalance Cost\n",
    "With the portfolio rebalanced, we need to use a metric to measure the cost of rebalancing the portfolio. Implement `get_rebalance_cost` to calculate the rebalance cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rebalance_cost(all_rebalance_weights, shift_size, rebalance_count):\n",
    "    \"\"\"\n",
    "    Get the cost of all the rebalancing.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    all_rebalance_weights : list of Ndarrays\n",
    "        ETF Returns for each ticker and date\n",
    "    shift_size : int\n",
    "        The number of days between each rebalance\n",
    "    rebalance_count : int\n",
    "        Number of times the portfolio was rebalanced\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rebalancing_cost  : float\n",
    "        The cost of all the rebalancing\n",
    "    \"\"\"\n",
    "    assert shift_size > 0\n",
    "    assert rebalance_count > 0\n",
    "    \n",
    "    #TODO: Implement function\n",
    "\n",
    "    return None\n",
    "\n",
    "project_tests.test_get_rebalance_cost(get_rebalance_cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to get the rebalance cost from  `get_rebalance_cost`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unconstrained_costs = get_rebalance_cost(all_rebalance_weights, shift_size, returns.shape[1])\n",
    "print(unconstrained_costs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Now that you're done with the project, it's time to submit it. Click the submit button in the bottom right. One of our reviewers will give you feedback on your project with a pass or not passed grade. You can continue to the next section while you wait for feedback."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
